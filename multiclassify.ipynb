{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.applications.vgg16 import preprocess_input,VGG16\n",
    "\n",
    "\n",
    "#from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "#from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "#from keras.models import load_weights\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Precison , Recall\n",
    "def precision(y_true, y_pred):\n",
    "    # Calculates the precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculates the recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmlPath = \"C:/Users/Parashara Ramesh/Desktop/PESU/AI/hackathon/images/VOCdevkit/VOC2010/Annotations/\"\n",
    "imgPath = \"C:/Users/Parashara Ramesh/Desktop/PESU/AI/hackathon/images/VOCdevkit/VOC2010/JPEGImages/\"\n",
    "#imgPath2 = \"C:/Users/Parashara Ramesh/Desktop/PESU/AI/hackathon/images/VOCdevkit/VOC2010/JPEGImages/\"\n",
    "\n",
    "labels=[\"aeroplane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\"cat\",\"chair\",\"cow\",\"diningtable\",\"dog\",\"horse\",\"motorbike\",\"person\",\"pottedplant\",\"sheep\",\"sofa\",\"train\",\"tvmonitor\"]\n",
    "\n",
    "imagewidth=150\n",
    "imageheight=150\n",
    "input_shape = (imageheight, imagewidth, 3)\n",
    "\n",
    "xtrain=[]\n",
    "ytrain = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape is  (5000, 20)\n"
     ]
    }
   ],
   "source": [
    "def createYtrain():\n",
    "    dirs = os.listdir(xmlPath)\n",
    "    count=0\n",
    "    for item in dirs[:5000]:\n",
    "        onehot=[0]*20\n",
    "        if os.path.isfile(xmlPath + item):\n",
    "            e = ET.parse(xmlPath + item)\n",
    "            root = e.getroot()\n",
    "            obj = root.findall('object')\n",
    "            tags=[]\n",
    "            for k in obj:\n",
    "                tags.append(k[0].text)\n",
    "            for tag in tags:\n",
    "                i = labels.index(tag)\n",
    "                onehot[i]=1\n",
    "            ytrain.append(onehot)\n",
    "\n",
    "createYtrain()\n",
    "ytrain=np.asarray(ytrain)\n",
    "print(\"y shape is \",ytrain.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xshape is  (5000, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "def createXtrain():\n",
    "    dirs = os.listdir(imgPath)\n",
    "    for item in dirs[:5000]:\n",
    "        if os.path.isfile(imgPath + item):\n",
    "            image = Image.open(imgPath+item)\n",
    "            resize = image.resize((imagewidth,imageheight), Image.NEAREST) \n",
    "            data = np.asarray(resize)\n",
    "            #data=np.asarray(image)\n",
    "            xtrain.append(data)\n",
    "\n",
    "createXtrain() \n",
    "xtrain=np.asarray(xtrain)\n",
    "print(\"xshape is \",xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created test and train data\n"
     ]
    }
   ],
   "source": [
    "def createTrainandTest():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(xtrain, ytrain, test_size=0.10, random_state=42)\n",
    "    return x_train,x_test,y_train,y_test\n",
    "x_train,x_test,y_train,y_test=createTrainandTest()\n",
    "print(\"created test and train data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now added\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 1,213,748\n",
      "Trainable params: 1,213,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "now compiling\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Conv2D parameters : Conv2D(32,(3,3), input_shape)\n",
    "#32 is the output shape\n",
    "#(3,3) is the filter size of the window in CNN\n",
    "#input_shape is input shape as said on the forums\n",
    "model.add(Conv2D(32,(3,3),input_shape = input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2))) #reducing pixels by 2,2\n",
    "\n",
    "#one more cnn layer\n",
    "model.add(Conv2D(32,(3,3),input_shape = input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "#one more cnn layer\n",
    "model.add(Conv2D(64,(3,3),input_shape = input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64)) #64 units underneath each CNN model\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5)) # alpha value that is the rate at which the training algorithm has to perform\n",
    "model.add(Dense(20)) #output layer is 1 i smy assumption\n",
    "#make dense 20 to get 20 classes as output\n",
    "#model.add(Activation('softmax'))\n",
    "model.add(Activation('sigmoid'))\n",
    "'''\n",
    "\n",
    "base_model=load_model('vgg16MODEL.h5')\n",
    "#base_model.save('vgg16MODEL.h5')\n",
    "print(\"loaded vgg16\")\n",
    "model = Sequential()\n",
    "vggmodel=base_model.layers[:-1]\n",
    "for l in vggmodel:\n",
    "    model.add(l)\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('sigmoid'))\n",
    "#model.add(Dropout(0.5))\n",
    "'''\n",
    "print(\"now added\")\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])#,precision,recall])\n",
    "print(model.summary())\n",
    "print(\"now compiling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "5000/5000 [==============================] - 16s - loss: 2.7680 - acc: 0.8155    \n",
      "Epoch 2/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.3450 - acc: 0.9007    \n",
      "Epoch 3/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2889 - acc: 0.9142    \n",
      "Epoch 4/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2777 - acc: 0.9181    \n",
      "Epoch 5/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2673 - acc: 0.9212    \n",
      "Epoch 6/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2590 - acc: 0.9234    \n",
      "Epoch 7/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2538 - acc: 0.9251    \n",
      "Epoch 8/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2456 - acc: 0.9269    \n",
      "Epoch 9/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2410 - acc: 0.9272    \n",
      "Epoch 10/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2374 - acc: 0.9283    \n",
      "Epoch 11/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2302 - acc: 0.9294    \n",
      "Epoch 12/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2249 - acc: 0.9302    \n",
      "Epoch 13/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2191 - acc: 0.9306    \n",
      "Epoch 14/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2120 - acc: 0.9325    \n",
      "Epoch 15/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2073 - acc: 0.9329    \n",
      "Epoch 16/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.2013 - acc: 0.9336    \n",
      "Epoch 17/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.1956 - acc: 0.9349    \n",
      "Epoch 18/18\n",
      "5000/5000 [==============================] - 10s - loss: 0.1908 - acc: 0.9353    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f7344417b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, epochs=18,batch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490/500 [============================>.] - ETA: 0s[0.14608442753925918, 0.94569999051094056]\n",
      "now saving the model\n",
      "finished saving now try testing!\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test,batch_size=2)\n",
    "print(score)\n",
    "\n",
    "print(\"now saving the model\")\n",
    "model.save('objdetector5096.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model\n",
    "\n",
    "print(\"finished saving now try testing!\")\n",
    "# returns a compiled model\n",
    "# identical to the previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
